{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings und Vektordatenbanken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings sind zentral in Anwendungen von großen Sprachmodellen (large language models LLMs). Im Wesentlichen handelt es sich dabei um dichte Vektorrepräsentationen von Wörtern, die semantische Beziehungen erfassen.\n",
    "\n",
    "#### Training und Funktion\n",
    "\n",
    "Embeddings werden durch unüberwachtes Lernen an großen Textkorpora trainiert, wobei Wörter mit ähnlichen Bedeutungen im Vektorraum nah beieinander positioniert werden.\n",
    "\n",
    "#### Nutzen\n",
    "\n",
    "Wort-Embeddings verbessern das Sprachverständnis des Modells, indem sie Wissen über Beziehungen zwischen Wörtern liefern, was genauere Vorhersagen und kontextbewusstere Antworten ermöglicht. Diese Embeddings ermöglichen ein gewisses Maß an semantischem Verständnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv  # zum laden von environment variablen\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from sklearn.metrics.pairwise import (\n",
    "    cosine_similarity,  # zum vergleichen zweier Vektoren\n",
    ")\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir verwenden hier ein Embedding-Modell von OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedder() -> AzureOpenAIEmbeddings:\n",
    "    \"\"\"Obtain an instance of the OpenAIEmbeddings class - a wrapper around the OpenAI API embedding functionality.\n",
    "\n",
    "    Returns:\n",
    "        OpenAIEmbeddings: an instance of the OpenAIEmbeddings class\n",
    "    \"\"\"\n",
    "    return AzureOpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein häufig verwendetes Modell ist \"text-embedding-ada-002\", wir verwenden den Nachfolger \"text-embedding-3\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = get_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedder.embed_query(\"This is a test query\")\n",
    "\n",
    "sns.lineplot(x=range(len(embeddings)), y=embeddings)\n",
    "plt.ylabel('Embedding Value')\n",
    "plt.xlabel('Dimension')\n",
    "plt.title('Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir beliebige Texte \"embedden\", und die Ähnlichkeit von zwei Texter via ihre embeddings vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_1 = embedder.embed_query(\"This is a test query\")\n",
    "embedding_2 = embedder.embed_query(\"This is another test query\")\n",
    "\n",
    "similarity_score = cosine_similarity([embedding_1], [embedding_2])[0, 0]\n",
    "\n",
    "print(f\"The similarity score is {similarity_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. Sehen Sie sich Embeddings anderer Eingaben an. Wie sehen diese aus? Welche Dinge sind tendenziell ähnlich/unähnlich? Können Sie längere Texte embedden, und macht das einen Unterschied? Können Sie andere Maße finden, die die Ähnlichkeit zwischen Embeddings bewerten?\n",
    "\n",
    "1.2. Können Sie den obigen Code erweitern, um ein Embedding für verschiedene Textsorten zu erstellen und einen \"maximal ähnlichen\" Text für eine spezifische Texteingabe zu finden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector stores und Similarity search\n",
    "\n",
    "Ein Vectorstore (oder Vektordatenbank) ist eine spezialisierte Datenbank, die darauf ausgelegt ist, semantische Suche von Texten mithilfe von Vektor-Embeddings zu ermöglichen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "document_1 = Document(page_content=\"Alice likes pizza.\", metadata={\"page\": 1})\n",
    "document_2 = Document(page_content=\"Bob loves pasta.\", metadata={\"page\": 2})\n",
    "document_3 = Document(page_content=\"This is a test document.\", metadata={\"page\": 1})\n",
    "document_4 = Document(page_content=\"This is another test document.\", metadata={\"page\": 1})\n",
    "\n",
    "vectorstore = InMemoryVectorStore(embedding=get_embedder())\n",
    "\n",
    "documents = [document_1, document_2, document_3, document_4]\n",
    "ids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vectorstore.add_documents(documents=documents, ids=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können die Vektordatenbank nun in einen \"retriever\" (quasi eine Suchmaschine) umwandeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 2, \"fetch_k\": 2, \"lambda_mult\": 0.5},\n",
    ")\n",
    "retriever.invoke(\"bob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgaben\n",
    "\n",
    "1.3. Welche Such-Parameter gibt es und was tun diese? Wie bekommen wir möglichst verschiedene Dokumente (in dem Fall, dass wir viele ähnliche Dokumente in der Datenbank haben)?\n",
    "\n",
    "1.4. Wie können wir nur die relevantesten Dokumente erhalten?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest\n",
    "\n",
    "Der \"Ingest\" Schritt bezeichnet das Laden und vorbereiten der \"knowledge base\" des RAG systems. Hierbei werden wir langchain Funktionen verwenden um ein oder meherere PDFs einzulesen, aufzuspalten und zusammein mit ihren embeddings in eine Vektordatenbank zu speichen.\n",
    "\n",
    "## Aufgabe\n",
    "\n",
    "1.5. Laden das angegebene PDF in eine Vektordatenbank.\n",
    "1.6. Teste die Suche mit der Vektordatenbank. Schaue dafür in das PDF und gib einen Suchbegriff ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"../data/Broschure-Sortiment-MicroFluidics.pdf\")\n",
    "# TODO: Lade das PDF-Dokument und weise es der Variable pdf_pages zu.\n",
    "pdf_pages = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Content: \\n {pdf_pages[0].page_content}')\n",
    "print('##########')\n",
    "print(f'Source: \\n {pdf_pages[0].metadata[\"source\"]}')\n",
    "print('##########')\n",
    "print(f'Page: \\n {pdf_pages[0].metadata[\"page\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
